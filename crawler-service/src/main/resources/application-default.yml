server.port: 8090
server.servlet.context-path: /api

debug: false
logging.level:
  root: INFO
  org.springframework.jdbc.core: DEBUG
  com.gargoylesoftware.htmlunit: ERROR

spring:
  datasource:
    url: jdbc:mysql://127.0.0.1:3306/website_crawler?useSSL=false&nullNamePatternMatchesAll=true&allowPublicKeyRetrieval=true
    username: root
    password: mypassword
    driver-class-name: com.mysql.cj.jdbc.Driver
    hikari:
      idle-timeout: 60000
  thymeleaf:
    cache: false

management:
  endpoints:
    web:
      exposure:
        include: health, info, metrics
      base-path: /
      path-mapping:
        health: healthcheck

server:
  compression:
    enabled: true
    mime-types: application/json
    min-response-size: 1024

cors:
  allowed-origins: "*"
  allowed-methods: HEAD,GET,PUT,POST,DELETE

crawler-settings:
  #Interval between each subsequent request (milliseconds)
  interval: 1000

  #Time limit for crawling an entire single site (seconds)
  time-limit: 300

  #task parallel size
  parallel-size: 12

  #Timeout for downloading a page (minutes)
  timeout-download: 2

  #Max number of times to retry a single page.
  retry-times: 2

  #Max depth that will be allowed to crawl for a site
  max-depth: 3

converter-settings:
  # Solr Client settings
  solr:
    base-url: "http://localhost:8983/solr"
  # Converter processing batch size: number of pages to read from the database in one batch
  batch-size: 500
  # Number of days since last modified for a page to be considered expired.
  time-lapse-period-in-days: 365
